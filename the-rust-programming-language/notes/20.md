# Final Project: Building A Multithreaded Web Server

Main protocols involved (you know this stuff, but noted here for completeness):

- **TCP** = Transmission Control Protocol
  - Lower-level protocol specifying *how* information is transmitted
  - Doesn't specify *what* the information is
- **HTTP** = Hypertext Transfer Protocol
  - Specifies the *contents* of requests/responses

Both protocols are *request-response*.

- Client initiates a request, server listens and responds.


# Creating a Single Threaded Web Server

See `projects/hello`

## HTTP Message Format

Text based protocol, with a defined structure for requests and responses.

### Request

```
+--------------------------------------+
| Method Request-URI HTTP-Version CLRF | -> Request Line
| headers CLRF                         | -> HTTP Headers
| message-body                         | -> Body Contents
+--------------------------------------+
```

For example:

```
Request: PUT / HTTP/1.1
Host: 127.0.0.1:7878
User-Agent: curl/7.65.3
Accept-Encoding: gzip, deflate
Accept: application/json, */*
Connection: keep-alive
Content-Type: application/json
Content-Length: 18
{"foo": "bar"}
```

- **Request Line** = information about **what** the client is requesting

### Response


```
+---------------------------------------------+
| HTTP-Version Status-Code Reason-Phrase CLRF | -> Status Line
| headers CLRF                                | -> HTTP Headers
| message-body                                | -> Body Contents
+---------------------------------------------+
```

For example:

```
HTTP/1.1 200 OK
Access-Control-Allow-Credentials: true
Access-Control-Allow-Origin: *
Connection: keep-alive
Content-Encoding: gzip
Content-Length: 276
Content-Type: application/json
Date: Sun, 19 Jan 2020 08:06:04 GMT
Referrer-Policy: no-referrer-when-downgrade
Server: nginx
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
{"foo": "bar"}
```

# Multithreaded Web Server

Again, you know this stuff but noting here for completeness.

Single thread is limited to handling a single client connection at a time.

- Low *throughput*
- A single slow request will prevent other requests from being handled

## Improving Throughput with a Thread Pool

**Thread pool** = group of *spawned* threads waiting to handle a task.

- Main program receives a new task, assigns it to a thread from the pool and
  can then continue handling other tasks.
- Thread returned to pool once task has been complete

Thread pool can be use to handle multiple requests concurrently.

- Increased throughput

Protect from *DoS* attacks by limiting thread pool to a *small* size.
- If the server created a *new* thread for *each* request, a DoS attack could be
  performed by making many requests (e.g. millions) and using up all the
  resources on the machine running the server.


Basic outline of approach:

1. Create a thread pool with a *fixed* number of threads
2. Main program sends incoming requests to the pool for processing
3. Pool places incoming requests into a **queue**
4. Threads in the pool repeatedly pop requests off the queue and process them

**1:1** correlation between number of threads and number of concurrent requests

- Server can handle as many concurrent requests as there are threads in the pool

